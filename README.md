# Introduction to Deep Learning

## Week 4: NLP Disaster Tweets Kaggle Mini-Project
## Natural Language Processing with Disaster Tweets

For this week’s mini-project, you will participate in this Kaggle competition: Natural Language Processing with Disaster Tweets.

This Kaggle competition is about classifying texts. It is an excellent introduction to Natural Language Processing (NLP). 

The project has 125 total points. The instructions summarize the criteria you will use to guide your submission and review others’ submissions. Note: to receive total points for this section, the learner doesn't need to have a top-performing score on the challenge. This is a mini-project to complete as a weekly assignment, so we don't expect you to iterate over your project until you have a model capable of winning the challenge. The learner needs to show a score that reasonably reflects that they completed the rubric parts of this project, E.g., a model score above 0.00000.  

You will submit three deliverables: 

## Deliverable 1

A Jupyter notebook with a description of the problem/data, exploratory data analysis (EDA) procedure, analysis (model building and training), result, and discussion/conclusion. 

Suppose your work becomes so large that it doesn’t fit into one notebook (or you think it will be less readable by having one large notebook). In that case, you can make several notebooks or scripts in a GitHub repository (as deliverable 3) and submit a report-style notebook or pdf instead.

If your project doesn’t fit into Jupyter notebook format (E.g., you built an app that uses ML), write your approach as a report and submit it in a pdf form. 

## Deliverable 2 

A public project GitHub repository with your work (please also include the GitHub repo URL in your notebook/report).

## Deliverable 3

A screenshot of your position on the Kaggle competition leaderboard for your top-performing model.


Review criteria
less 
Three of your peers will review each of your three deliverables (Jupyter notebook or pdf report, GitHub repository, and challenge leaderboard screenshot) based on the rubrics for each deliverable.

Use the rubrics to guide your project to include all parts for the grade you want to achieve. The project has 125 total points.


## Instructions: Step 1
 
**Brief description of the problem and data (5 pts)**

Briefly describe the challenge problem and NLP. Describe the size, dimension, structure, etc., of the data. 

## Instructions: Step 2
 
**Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data (15 pts)**

Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis? 

## Instructions: Step 3
 
**Model Architecture (25 pts)**

Describe your model architecture and reasoning for why you believe that specific architecture would be suitable for this problem. 

Since we did not learn NLP-specific techniques such as word embeddings in the lectures, we recommend looking at Kaggle tutorials, discussion boards, and code examples posted for this challenge.  You can use any resources needed, but make sure you “demonstrate” you understood by including explanations in your own words. Also importantly, please have a reference list at the end of the report.  

There are many methods to process texts to matrix form (word embedding), including TF-IDF, GloVe, Word2Vec, etc. Pick a strategy and process the raw texts to word embedding. Briefly explain the method(s) and how they work in your own words.

Build and train your sequential neural network model (You may use any RNN family neural network, including advanced architectures LSTM, GRU, bidirectional RNN, etc.). 

## Instructions: Step 4
 
**Results and Analysis (35 pts)**

Run hyperparameter tuning, try different architectures for comparison, apply techniques to improve training or performance, and discuss what helped.

Includes results with tables and figures. There is an analysis of why or why not something worked well, troubleshooting, and a hyperparameter optimization procedure summary.


## Instructions: Step 5
 
**Conclusion (15 pts)**

Discuss and interpret results as well as learnings and takeaways. What did and did not help improve the performance of your models? What improvements could you try in the future?





## Instructions: Step 6

**Produce Deliverables:** High-Quality, Organized Jupyter Notebook Report, GitHub Repository, and screenshot of Kaggle leaderboard (30 points)
These deliverables serve two purposes- grade for this course and your project portfolio that you can show when you apply for jobs.

For the sake of this project, you can use GitHub to showcase your codebase. In the real world, versioning with GitHub is vital for collaboration. Sometimes Jupyter notebooks don’t seem particularly well-suited to versioning with GitHub due to hard-to-read diffs and the like. If you want to use this project as an opportunity to practice versioning with GitHub, consider something like the following: https://www.reviewnb.com.

# Instructions: Peer Review
 
One of the essential components of this project is peer review. In this project, you gain hands-on experience on Kaggle, a famous platform for data science competitions. To further your professional development, think of your peers as work colleagues. Communicate how you approached this critical task! Organize and appropriately comment on your codebase so that your co-workers can collaborate on it and maintain it. What can you learn from how your peers approached this project? 
